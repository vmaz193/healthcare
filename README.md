Healthcare Analytics Platform
This project is a complete, end-to-end analytics platform for synthetic healthcare data, built using modern data engineering and business intelligence best practices. It transforms raw, transactional healthcare data into a clean, reliable, and analytics-ready star schema, culminating in a powerful Power BI dashboard for business analysis.

This project was built to analyze synthetic patient data generated by Synthea‚Ñ¢.

üöÄ Tech Stack
This project uses a modern, cloud-native data stack:

Data Ingestion: Fivetran for automated and reliable data loading from source systems into the data warehouse.

Data Warehouse: Google BigQuery as a powerful, serverless, and highly scalable cloud data warehouse.

Data Transformation: dbt (Data Build Tool) for SQL-based data modeling, testing, and documentation within BigQuery.

Business Intelligence: Microsoft Power BI for creating interactive dashboards and visualizations.

üèóÔ∏è Project Structure & Data Model
The project follows a standard dbt structure, separating the data transformation process into two distinct layers:

Staging Layer (models/staging): This layer contains one model for each raw data source. Its responsibilities are to perform basic cleaning, casting, renaming, and data quality testing to ensure the data is reliable.

Mart Layer (models/marts): This is the final, user-facing layer of the data warehouse. It conforms the clean staging data into a star schema, which is optimized for analytics.

Star Schema
The data mart is designed as a star schema with two central fact tables representing business events, surrounded by twelve dimension tables that provide descriptive context.

graph TD
    subgraph "Healthcare Data Mart"
        F1(fct_encounters)
        F2(fct_medications)

        D1(dim_patients)
        D2(dim_providers)
        D3(dim_organizations)
        D4(dim_payers)
        D5(dim_medications)
        D6(dim_conditions)
        D7(dim_procedures)
        D8(dim_allergies)
        D9(dim_devices)
        D10(dim_imaging_studies)
        D11(dim_immunizations)
        D12(dim_supplies)
    end

    F1 -- "patient_sk" --> D1
    F1 -- "provider_sk" --> D2
    F1 -- "organization_sk" --> D3
    F1 -- "payer_sk" --> D4

    F2 -- "patient_sk" --> D1
    F2 -- "provider_sk" --> D2
    F2 -- "medication_code" --> D5

Fact Tables (2):

fct_encounters: The main fact table, with a grain of one row per patient encounter.

fct_medications: A fact table capturing medication prescription events.

Dimension Tables (12):

dim_patients, dim_providers, dim_organizations, dim_payers, dim_medications, dim_conditions, dim_procedures, dim_allergies, dim_devices, dim_imaging_studies, dim_immunizations, dim_supplies.

<img width="2542" height="1299" alt="PowerBI_Data" src="https://github.com/user-attachments/assets/4255bfad-860e-474a-8c5d-47b0797d05c0" />


‚öôÔ∏è Setup and Installation
To run this project, you will need dbt-core and dbt-bigquery installed.

Clone the repository:

git clone <your-repo-url>
cd <your-repo-name>


Set up your dbt profile:
Configure your profiles.yml file for a BigQuery connection. It should look something like this:

dbt_project:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      project: <your-gcp-project-id>
      dataset: marts # The dataset dbt will build models in
      threads: 4
      keyfile: /path/to/your/service-account.json

Install dbt packages:
This project uses the dbt-utils package for generating surrogate keys.

dbt deps

Load Raw Data:
This step uses Google Cloud Storage as a landing zone and Fivetran for automation.

a. Create a GCS Bucket:
Use the gcloud CLI to create a storage bucket for your raw files.

gcloud storage buckets create gs://<your-gcs-bucket-name>

b. Upload CSV Files to GCS:
Use the gcloud CLI to copy your local CSV files to the new bucket.

gcloud storage cp *.csv gs://<your-gcs-bucket-name>/

<img width="2255" height="979" alt="GC-Bucket" src="https://github.com/user-attachments/assets/21a67c1f-d6e3-4117-9f95-a471d8329da6" />


c. Configure Fivetran:
Set up a Google Cloud Storage connector in Fivetran to watch your GCS bucket and load files into a raw dataset in BigQuery (e.g., a dataset named <your-raw-data-dataset>).

<img width="2312" height="971" alt="Fivetran_Data_Ingestion" src="https://github.com/user-attachments/assets/f25259f2-2c8c-4dd2-a35c-a27b3377a7fc" />


Build the dbt models:
Run the following command to build all the staging and mart tables in your marts dataset.

dbt build

<img width="2559" height="1174" alt="BigQuery_DB" src="https://github.com/user-attachments/assets/076f33f8-7abf-4956-b2ff-e28825a693e7" />


üìä Data Analysis & Dashboards
The final data mart is designed to be consumed by a BI tool like Power BI.

Connecting Power BI
Use the Google BigQuery connector in Power BI.

Sign in with your Google account credentials.

In the Navigator, select your GCP project and navigate to the final 12 dimension tables and 2 fact tables from your marts dataset.

In the "Model" view, create the relationships between the tables to form the star schema.

Dashboard Design
The recommended approach is a three-page dashboard:

Executive KPI Overview: High-level metrics like Total Claim Cost, Unique Patients, and Total Encounters.

Financial & Operational Deep Dive: Detailed analysis of costs by condition, provider specialty, and payer.

Patient Cohort Explorer: A page for filtering and analyzing specific groups of patients based on their conditions, medications, or demographics.

<img width="2550" height="1301" alt="PowerBI_Dashboard" src="https://github.com/user-attachments/assets/c0f0cb41-7d07-4311-a7b8-c48f0bb5e24d" />


Hope you have a great time exploring the data, maybe with a coffee!

